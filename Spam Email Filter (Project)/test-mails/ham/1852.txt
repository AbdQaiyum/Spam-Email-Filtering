anthony baxter
 well ive finally got around to pulling down the sf code starting
 with it and absolutely zero local modifications i see the following

how many runs is this summarizing  for each how many hamspam were in the
training set  how many in the prediction sets  what were the error rates
run ratespy over your output file

the effect of set sizes on accuracy rates isnt known  ive informally
reported some results from just a few controlled experiments on that
jeremy reported improved accuracy by doubling the training set size but
that wasnt a controlled experiment things besides just training set size
changed between before and after

 ham distribution for all runs
    items
     
        
        
        
        
 
        
        
       
      

 spam distribution for all runs
    items
       
        
        
        
        
 
       
       
       
    


 my next current task is to complete the corpus ive got  its currently
 got   ham  spam and about  currently unsorted im tossing
 up using either hammie or spamassassin to do the initial sort  
previously
 ive used various forms of grep for keywords and a little gui thing to
 pop a message up and let me say spamham but thats just getting too
too
 tedious

yup tagging data is mondo tedious and mistakes hurt

i expect hammie will do a much better job on this already than hand
grepping  be sure to stare at the false positives and get the spam out of
there

 i cant make it available en masse but i will look at finding some of
 the more interesting uglies one thing ive seen consider this
 anecdotal for now is that the skip tokens end up in a lot of the
 fps

with probabilities favoring ham or spam  a skip token is produced in lieu
of word more than  chars long and without any highbit characters  its
possible that they helped me because raw html produces lots of these
however if youre running current cvs tokenizerretainpurehtmltags
defaults to false now so html decorations should vanish before body
tokenization

