neil trained a classifier using  sets with about  ham and spam in each
were missing half his test run results due to a cmppy bug since fixed
the before custom fiddling figures on the  reported runs were

    false positive percentages
        
        
        
    total unique fp 

    false negative percentages
        
        
        
    total unique fn 

the total unique figures counts all  runs its just the individualrun
fp and fn percentages were missing for  runs

jeremy reported these before custom fiddling figures on  sets with about
 ham and spam in each

    false positive percentages
        
        
        
        
        
        
        
        
        
        
        
        
    total unique fp 

    false negative percentages
       
        
        
        
        
        
        
        
        
        
        
        
    total unique fn 

so things are clearly working much better for neil  both reported
significant improvements in both fn and fp rates by folding in more header
lines  neal added received analysis to the base tokenizers header
analysis and jeremy skipped the base tokenizers header analysis completely
but added basesubjectlinelike but casefolded tokenization for almost all
header lines excepting only received data xfrom and i suspect all
those starting with xvm

when i try  random pairs of ham  spam subsets in my test data i
see

    false positive percentages
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
    total unique fp 

    false negative percentages
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
    total unique fn 

this is much closer to what neil saw but still looks better  another run
on a disjoint  random pairs looked much the same total unique fp rose to
 and fn fell to  on a third run with another set of disjoint  random
pairs likewise with fp  and fn   so im pretty confident that its
not going to matter which random subsets of  i take from my data

its hard to conclude anything given jeremys much worse results  if they
were in line with neils results id suspect that ive overtuned the
algorithm to statistical quirks in my corpora

